{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Loaded Model from disk\n",
      "Loaded Model Weights from disk\n",
      "[[ 0.001  0.993  0.000  0.000  0.006]]\n",
      "[1]\n",
      "BENEFIT\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "import imutils\n",
    "import os\n",
    "import time\n",
    "import timeit\n",
    "import itertools\n",
    "import dlib\n",
    "\n",
    "from imutils import face_utils\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Convolution3D, ZeroPadding3D, Activation, MaxPooling3D, Flatten, Dropout, BatchNormalization\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import SGD, rmsprop, Adam\n",
    "from keras.models import model_from_json\n",
    "from keras.utils import to_categorical, plot_model\n",
    "\n",
    "np.random.seed(7)\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "# sizes of mouth region -> input shape\n",
    "IMG_ROWS = 35\n",
    "IMG_COLS = 50\n",
    "VID_DEPTH = 28\n",
    "\n",
    "\n",
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "p = \"shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)\n",
    "\n",
    "\n",
    "# selected subset of words for training\n",
    "selected = [\"AGREEMENT\", \"BENEFIT\", \"CONSERVATIVE\", \"CUSTOMERS\", \"EXPECTED\"]\n",
    "print(len(selected))\n",
    "\n",
    "\n",
    "model_name = \"model\"\n",
    "models_dir = 'models/'\n",
    "\n",
    "\n",
    "def load_model(model_path, model_weights_path):\n",
    "\n",
    "    json_file = open(model_path, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(model_weights_path)\n",
    "    print(\"Loaded Model from disk\")\n",
    "\n",
    "    # compile and evaluate loaded model\n",
    "    loaded_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    print(\"Loaded Model Weights from disk\")\n",
    "\n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "model = load_model(models_dir + model_name + '.json', models_dir + model_name + '.h5')\n",
    "\n",
    "\n",
    "def convert_video_to_3d_array(video):\n",
    "    cap = cv2.VideoCapture(video)\n",
    "\n",
    "    cnt = 0\n",
    "   \n",
    "    lipsFrames = []\n",
    "        \n",
    "    current_video_array = None\n",
    "\n",
    "    while cap.isOpened():\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret == True:\n",
    "        \n",
    "            # convert frame to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # detect faces in the grayscale image\n",
    "            rects = detector(gray, 0)\n",
    "        \n",
    "            # loop over the face detections\n",
    "            for (i, rect) in enumerate(rects):\n",
    "                # determine the facial landmarks for the face region, then\n",
    "                # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "                # array\n",
    "                global shape\n",
    "                shape = predictor(gray, rect)\n",
    "                shape = face_utils.shape_to_np(shape)\n",
    "            \n",
    "            # crop_img = frame[top:bottom, left:right]\n",
    "            crop = gray[ shape[14][1]:shape[11][1], shape[6][0]:shape[10][0]]\n",
    "            crop = cv2.resize(crop, (IMG_COLS,IMG_ROWS))\n",
    "            #cv2.imwrite(\"araba\"+str(count)+\".jpg\", crop)     # save frame as JPG file\n",
    "        \n",
    "            lips_resized = cv2.resize(crop, (IMG_COLS, IMG_ROWS), interpolation=cv2.INTER_AREA)\n",
    "            lipsFrames.append(lips_resized)\n",
    "                \n",
    "                    \n",
    "        # if video is empty, skip the sample\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        cnt += 1\n",
    "        if cnt > VID_DEPTH:\n",
    "            current_video_array = np.array(lipsFrames, dtype=\"uint8\")\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    return current_video_array\n",
    "\n",
    "\n",
    "np_frame_array = convert_video_to_3d_array('predict_word.mp4')\n",
    "np.save('c:\\odev\\predict_word.npy', np_frame_array)\n",
    "\n",
    "\n",
    "sample = np.load('c:\\odev\\predict_word.npy')\n",
    "sample = (sample.astype(\"float16\") - 128) / 128  # normalize to 0 - 1\n",
    "\n",
    "sample = np.array(sample)\n",
    "sample = np.expand_dims(sample, axis=0)\n",
    "sample = sample.reshape(sample.shape + (1,))\n",
    "\n",
    "\n",
    "\n",
    "prediction = model.predict(sample)\n",
    "print(prediction)\n",
    "\n",
    "prediction_class = np.argmax(prediction, axis=1)\n",
    "print(prediction_class)\n",
    "\n",
    "print(selected[prediction_class[0]])\n",
    "print(prediction_class[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
